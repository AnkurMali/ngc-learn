# Spiking Neural Networks: Learning with Broadcast Feedback Alignment

In this exhibit, we will see how one can train a spiking neural network model
using surrogate functions and a credit assignment scheme called broadcast
feedback alignment (BFA) <b>[1]</b>.
This exhibit model effectively reproduces some of the results
reported (Samadi et al., 2017) <b>[1]</b>. The model code for this
exhibit can be found `here`.
<!--[here](https://github.com/NACLab/ngc-museum/tree/main/exhibits/bfa_snn).-->

Note: You will need to unzip the MNIST arrays in `exhibits/data/mnist.zip` to the
folder `exhibits/data/` to work through this exhibit/walkthrough.

## Building with the Simplified Leaky-Integrate-and-Fire

## Credit Assignment under Broadcast Feedback Alignment

### Using an In-Built Surrogate Function

## References

[1] Samadi, Arash, Timothy P. Lillicrap, and Douglas B. Tweed. "Deep learning with dynamic spiking neurons and fixed feedback weights." Neural computation 29.3 (2017): 578-602.
[2] Hodgkin, Alan L., and Andrew F. Huxley. "A quantitative description of membrane current and its application to conduction and excitation in nerve." The Journal of physiology 117.4 (1952): 500.
